Okay, now that you have seen how matrix multiplication with a vector can be seen as a transformation, what I want to tell you is, let's say you had a vector x, and upon transformation, this vector got transformed to another vector b. And you want to bring it back to x. 
That is the case when you are, what you are doing when you essentially trying to solve A X equal to B, right? 
You have the value for B and you have this transformation that you applied to X to get to B. And now what do you want this? 
You want the original value of X. So basically now you want another transformation that can take B as input and get you back to X. So this transformation is basically called A inverse, right? 
And like the original transformation, 
if you multiply the given vector B with this transformation, it will definitely get you back to X, right? 
Now, what do you think, as Ritesh has already motivated sequential multiplication of matrices as subsequent transformations, what do you think that this matrix represents? 
This is actually nothing but applying this or this, anything. 
This is nothing but applying a transformation on the vector x and then applying another transformation on the transform vector. 
And we just saw that if you apply this transformation to x, you'll go to b and then you apply the inverse transformation, it will again come back to x. That essentially means this entire multiplication will result into x. 
right and if you look at this equation you can easily deduce that A inverse A should be an identity matrix for this equation to hold right yeah so far we have talked about the cases where you can actually find out this inverse matrices and which is mostly in the case of square matrices that you are able to find out this inverse 
